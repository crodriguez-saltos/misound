@Article{tchernichovski_procedure_2000,
  title = {A Procedure for an Automated Measurement of Song Similarity},
  volume = {59},
  issn = {0003-3472},
  abstract = {Assessment of vocal imitation requires a widely accepted way of describing and measuring any similarities between the song of a tutor and that of its pupil. Quantifying the similarity between two songs, however, can be difficult and fraught with subjective bias. We present a fully automated procedure that measures parametrically the similarity between songs. We tested its performance on a large database of zebra finch, Taeniopygia guttata, songs. The procedure uses an analytical framework of modern spectral analysis to characterize the acoustic structure of a song. This analysis provides a superior sound spectrogram that is then reduced to a set of simple acoustic features. Based on these features, the procedure detects similar sections between songs automatically. In addition, the procedure can be used to examine: (1) imitation accuracy across acoustic features; (2) song development; (3) the effect of brain lesions on specific song features; and (4) variability across different renditions of a song or a call produced by the same individual, across individuals and across populations. By making the procedure available we hope to promote the adoption of a standard, automated method for measuring similarity between songs or calls.},
  number = {6},
  journal = {Animal Behaviour},
  doi = {10.1006/anbe.1999.1416},
  author = {Ofer Tchernichovski and Fernando Nottebohm and Ching Elizabeth Ho and Bijan Pesaran and Partha Pratim Mitra},
  month = {jun},
  year = {2000},
  pages = {1167-1176},
  file = {/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/J72W3B4G/Tchernichovski et al. - 2000 - A procedure for an automated measurement of song s.pdf;/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/PWKNX9P4/Tchernichovski et al_2000_A procedure for an automated measurement of song similarity.pdf;/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/4VW9TFHW/S0003347299914161.html;/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/UF2GNGGU/S0003347299914161.html},
}

@Article{mandelblat-cerf_automated_2014-1,
  title = {An {{Automated Procedure}} for {{Evaluating Song Imitation}}},
  volume = {9},
  issn = {1932-6203},
  abstract = {Songbirds have emerged as an excellent model system to understand the neural basis of vocal and motor learning. Like humans, songbirds learn to imitate the vocalizations of their parents or other conspecific ``tutors.'' Young songbirds learn by comparing their own vocalizations to the memory of their tutor song, slowly improving until over the course of several weeks they can achieve an excellent imitation of the tutor. Because of the slow progression of vocal learning, and the large amounts of singing generated, automated algorithms for quantifying vocal imitation have become increasingly important for studying the mechanisms underlying this process. However, methodologies for quantifying song imitation are complicated by the highly variable songs of either juvenile birds or those that learn poorly because of experimental manipulations. Here we present a method for the evaluation of song imitation that incorporates two innovations: First, an automated procedure for selecting pupil song segments, and, second, a new algorithm, implemented in Matlab, for computing both song acoustic and sequence similarity. We tested our procedure using zebra finch song and determined a set of acoustic features for which the algorithm optimally differentiates between similar and non-similar songs.},
  number = {5},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0096484},
  author = {Yael Mandelblat-Cerf and Michale S. Fee},
  month = {may},
  year = {2014},
  keywords = {Acoustics,Algorithms,Birds,Imitation,Sequence motif analysis,Syllables,bird song,zebra finch},
  pages = {e96484},
  file = {/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/6KBM8UC5/Mandelblat-Cerf and Fee - 2014 - An Automated Procedure for Evaluating Song Imitati.pdf;/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/V7MIP6J2/article.html},
}
@Article{mets_automated_2018,
  title = {An Automated Approach to the Quantitation of Vocalizations and Vocal Learning in the Songbird},
  volume = {14},
  issn = {1553-7358},
  abstract = {Studies of learning mechanisms critically depend on the ability to accurately assess learning outcomes. This assessment can be impeded by the often complex, multidimensional nature of behavior. We present a novel, automated approach to evaluating imitative learning. Conceptually, our approach estimates how much of the content present in a reference behavior is absent from the learned behavior. We validate our approach through examination of songbird vocalizations, complex learned behaviors the study of which has provided many insights into sensory-motor learning in general and vocal learning in particular. Historically, learning has been holistically assessed by human inspection or through comparison of specific song features selected by experimenters (e.g. fundamental frequency, spectral entropy). In contrast, our approach uses statistical models to broadly capture the structure of each song, and then estimates the divergence between the two models. We show that our measure of song learning (the Kullback-Leibler divergence between two distributions corresponding to specific song data, or, Song DKL) is well correlated with human evaluation of song learning. We then expand the analysis beyond learning and show that Song DKL also detects the typical song deterioration that occurs following deafening. Finally, we illustrate how this measure can be extended to quantify differences in other complex behaviors such as human speech and handwriting. This approach potentially provides a framework for assessing learning across a broad range of behaviors like song that can be described as a set of discrete and repeated motor actions.},
  language = {en},
  number = {8},
  journal = {PLOS Computational Biology},
  doi = {10.1371/journal.pcbi.1006437},
  author = {David G. Mets and Michael S. Brainard},
  month = {aug},
  year = {2018},
  keywords = {Behavior,Bird song,Birds,Learning,Speech,Statistical models,Syllables,Vocalization},
  pages = {e1006437},
  file = {/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/NJZ6A583/Mets and Brainard - 2018 - An automated approach to the quantitation of vocal.pdf;/home/carlosr-work/.zotero/zotero/ws6wt8hy.default/zotero/storage/CNQ63ZT4/article.html},
}
